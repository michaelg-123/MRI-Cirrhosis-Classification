{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow\n",
    "- Input data \n",
    "    - NifTI images \n",
    "- Preprocessing if needed\n",
    "- Feature extraction \n",
    "    - PyRadiomics\n",
    "- Model development\n",
    "    - Neural network?\n",
    "    - Random forest?\n",
    "\n",
    "*Note*\n",
    "- I had to create a virtual environment using conda in order to install pyradiomics which I believe only works on specific versions of python*\n",
    "- I also had to downgrade numpy to use pyradiomics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Radiomic Feature Extractor (PyRadiomics)\n",
    "### Important Notes: \n",
    "- This portion of the project is essentially creating our own dataset of features from which to perform ML classification tasks\n",
    "- Features extracted\n",
    "    - The current baseline for this is using the default settings on Pyradiomics feature extractor https://pyradiomic.readthedocs.io/en/latest/features.html \n",
    "        - First order statistics (19 features)\n",
    "        - Shap-based 3D (16 features)\n",
    "        - Shape-based 2D (10 features)\n",
    "        - Gray level Co-occurence Matrix (24 features)\n",
    "        - Gray Level Size Zone Matrix (16 features)\n",
    "        - Gray Level Run Length Matrix (16 features)\n",
    "        - Neighbouring Gray Tone Difference Matrix (5 features)\n",
    "        - Gray level Dependence Matrix (14 features)\n",
    "    - *Moving forward there is a lot of room to better understand this and the customization of it*\n",
    "    - Customization: Choose the best features to craft a dataset optimized for our images/task\n",
    "### Runtime Note:\n",
    "*Using the default feature extractor this is a very long runtime. In theory it should only have to be done once and the features can be imported to a pandas dataframe*\n",
    "- Run time ~ 2 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Need to pair the images with the masks to be used in the feature extractor\n",
    "def pair(image_dir, mask_dir):\n",
    "    image_files = [f for f in os.listdir(image_dir) if f.endswith('.nii.gz')]\n",
    "    mask_files = [f for f in os.listdir(mask_dir) if f.endswith('.nii.gz')]\n",
    "    \n",
    "    image_mask_pairs = {}\n",
    "    \n",
    "    for image_file in image_files:\n",
    "        if image_file in mask_files:\n",
    "            image_mask_pairs[image_file] = image_file  # Both the image and mask have the same name\n",
    "    \n",
    "    return image_mask_pairs\n",
    "\n",
    "train_pairs_T1 = pair(train_images_T1, train_masks_T1)\n",
    "valid_pairs_T1 = pair(valid_images_T1, valid_masks_T1)\n",
    "test_pairs_T1 = pair(test_images_T1, test_masks_T1)\n",
    "\n",
    "train_pairs_T2 = pair(train_images_T2, train_masks_T2)\n",
    "valid_pairs_T2 = pair(valid_images_T2, valid_masks_T2)\n",
    "test_pairs_T2 = pair(test_images_T2, test_masks_T2)\n",
    "\n",
    "# Verify pairs\n",
    "print(\"T1 Train Pairs:\", train_pairs_T1)\n",
    "print(\"T1 Valid Pairs:\", valid_pairs_T1)\n",
    "print(\"T1 Test Pairs:\", test_pairs_T1)\n",
    "len(train_pairs_T1)\n",
    "len(valid_pairs_T1)\n",
    "len(test_pairs_T1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize the feature extractor\n",
    "extractor = featureextractor.RadiomicsFeatureExtractor()\n",
    "\n",
    "def extract_features_for_pairs(image_mask_pairs, image_dir, mask_dir):\n",
    "    all_features = []\n",
    "    \n",
    "    for image_file, mask_file in image_mask_pairs.items():\n",
    "        # Load the image and mask using SimpleITK\n",
    "        image_path = os.path.join(image_dir, image_file)\n",
    "        mask_path = os.path.join(mask_dir, mask_file)\n",
    "\n",
    "        image = sitk.ReadImage(image_path)\n",
    "        mask = sitk.ReadImage(mask_path)\n",
    "        \n",
    "        # Extract features using Pyradiomics\n",
    "        features = extractor.execute(image, mask)\n",
    "        \n",
    "        # Convert features to a dictionary and add to the list\n",
    "        feature_dict = {key: value for key, value in features.items()}\n",
    "        all_features.append(feature_dict)\n",
    "    \n",
    "    return all_features\n",
    "\n",
    "# Extract features for training, validation, and test sets for T1\n",
    "train_features_T1 = extract_features_for_pairs(train_pairs_T1, train_images_T1, train_masks_T1)\n",
    "valid_features_T1 = extract_features_for_pairs(valid_pairs_T1, valid_images_T1, valid_masks_T1)\n",
    "test_features_T1 = extract_features_for_pairs(test_pairs_T1, test_images_T1, test_masks_T1)\n",
    "\n",
    "# Extract features for T2 images\n",
    "train_features_T2 = extract_features_for_pairs(train_pairs_T2, train_images_T2, train_masks_T2)\n",
    "valid_features_T2 = extract_features_for_pairs(valid_pairs_T2, valid_images_T2, valid_masks_T2)\n",
    "test_features_T2 = extract_features_for_pairs(test_pairs_T2, test_images_T2, test_masks_T2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Pass it to pandas \n",
    "df_train_T1 = pd.DataFrame(train_features_T1)\n",
    "df_valid_T1 = pd.DataFrame(valid_features_T1)\n",
    "df_test_T1 = pd.DataFrame(test_features_T1)\n",
    "\n",
    "df_train_T2 = pd.DataFrame(train_features_T2)\n",
    "df_valid_T2 = pd.DataFrame(valid_features_T2)\n",
    "df_test_T2 = pd.DataFrame(test_features_T2)\n",
    "\n",
    "# Save the DataFrames to CSV files\n",
    "df_train_T1.to_csv('train_features_T1.csv', index=False)\n",
    "df_valid_T1.to_csv('valid_features_T1.csv', index=False)\n",
    "df_test_T1.to_csv('test_features_T1.csv', index=False)\n",
    "\n",
    "df_train_T2.to_csv('train_features_T2.csv', index=False)\n",
    "df_valid_T2.to_csv('valid_features_T2.csv', index=False)\n",
    "df_test_T2.to_csv('test_features_T2.csv', index=False)\n",
    "\n",
    "#These are now the datasets for which we can do ML with"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
